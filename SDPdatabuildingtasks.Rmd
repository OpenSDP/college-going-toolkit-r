---
title: "SDP Data Building Tasks"
author: "Strategic Data Project"
date: "October 31, 2016"
output: html_document
---


# SDP Data Building Tasks


```{r, echo = FALSE, error = FALSE, message = FALSE, comment = NA}
# Set options for knitr
library(knitr)
opts_knit$set(comment = NA, warning = FALSE, error = FALSE, message = FALSE, 
              fig.path = "figure/task3-", dev = c('pdf', 'png'))
options(width=120)
```

## Overview

Housed at the Center for Education Policy Research at Harvard University, the 
Strategic Data Project (SDP) partners with school districts, school networks, 
and state agencies across the US. **Our mission is to transform the use of 
data in education to improve student achievement.** We believe that with the 
right people, the right data, and the right analyses, we can significantly 
improve the quality of strategic policy and management decisions. 

### Core Strategies
To achieve our mission, SDP pursues three core strategies: 

1. Placing top-notch analytic leaders as ``Fellows'' for two years with our 
partner agencies; 
\noindent{\small SDP supports more than 40 Data and Agency Fellows serving 
partner educational agencies -- districts, states, and charter management 
organizations--across the nation.  This number will grow to nearly 70 in 2012.} 

2. Conducting rigorous diagnostic analyses of teacher effectiveness and 
college-going success using existing agency data; and 

\noindent{\small We have completed diagnostics in teacher effectiveness 
and / or college-going success in seven districts, with more diagnostics 
currently underway or planned in additional district 
and state partner agencies.} 

3. Disseminating our tools, methods, and lessons learned to many more education 
agencies. 

\noindent{\small Through the diagnostic analyses, we have developed a body of 
knowledge around effective data use.  The release of this toolkit reflects SDP's 
third core strategy to spread knowledge and build capacity within educational 
agencies for effective data use.} 


### SDP DIAGNOSTICS

Our second core strategy, conducting rigorous diagnostic analyses using existing 
agency data, focuses on two core areas: **(1) college-going success and 
attainment for students and (2) human capital** (primarily examining teacher 
effectiveness).

The diagnostics are a set of analyses that frame actionable questions for 
education leaders.  By asking questions such as, 
*How well do students transition to postsecondary education?* or 
*How successfully is an agency recruiting effective teachers?* we support 
education leaders to develop a deep understanding of student achievement in 
their agency. In an effort to make these analyses accessible and more widely 
used, this toolkit helps analysts collect data and produce analyses associated 
with the SDP College-Going and Human Capital diagnostics. 

Notably, the diagnostic analyses in this release of our toolkit are specific to 
the College-Going diagnostic.  The data collection (Identify), data cleaning 
(Clean), and best practices (Adopt) stages of the toolkit, however, are 
applicable to either diagnostic and convey general data use guidelines valuable 
to any analysts interested in increasing the quality and rigor of their analyses. 
Later releases will address the analyses in our Human Capital diagnostic.

## Introduction
### SDP Data Building Tasks

\normalsize
Congratulations on identifying the data elements that are essential for 
conducting rigorous analyses in your organization. **Clean** is the next stage 
in the SDP Toolkit for Effective Data Use.  To successfully move through the 
**Clean** stage, you should review the  **Identify** component of this toolkit.  
Upon completing this stage, you will have produced clean research files that 
will allow you to **Connect** and **Analyze** data related to college-going 
success in your agency.

### THE TASKS

**Clean** consist of five tasks that share a similar structure.  The tasks are 
geared toward analysts with at least moderately strong data background and 
comfort with statistics.  Each task provides hands-on experience building 
specific components of the research file used for the SDP CollegeGoing 
Diagnostic Analyses.

The tasks are listed as follows:
- Task 1 Student Attributes
- Task 2 Student School Year
- Task 3 Identifying the Ninth Grade Cohort
- Task 4 Student School Enrollment
- Task 5 Prior Achievement

Each task is accompanied by a practice file dataset upon which all data 
snapshots and output are based. These datasets consist of simulated data that 
have been fully de-identified.We strongly recommend that you use these datasets 
to work through the tasks and check your answers.  The datasets are available 
for download at (www.gse.harvard.edu/sdp/tools)[www.gse.harvard.edu/sdp/tools]. 
Note that the tasks follow a logical sequence from Task 1 to Task 5, and some 
tasks require the output of previous tasks.  However, because we provide all 
necessary practice files for each task, you may also choose to work on the tasks 
out of order.  For instance, you may be first interested in identifying the 
ninth-grade cohort for students in your agency with Task 3. 

To successfully complete all parts of this toolkit, however, you should work 
your way through all five tasks.  The output of each task will be needed to 
successfully complete the Connect and Analyze stages of the toolkit. Lastly, it 
is important to note that the tasks do not show you how to develop every single 
component and detail of the files to be used in Connect and Analyze.  Our goal 
is to equip you with an understanding for the core process of constructing 
robust, clean research files.  We do, however, aim to explicitly indicate what 
additional elements are needed in the `DATA DESCRIPTION` section of each task to 
deliver a fully realized research file.  Furthermore, we also provide a 
`DECISION RULES GLOSSARY` in the Appendix at the end of this document to provide 
guidance on how to approach the cleaning process for these additional elements.

For those who are less familiar with or who need to brush up on Stata use, we 
also include a `R GLOSSARY` of commonly used commands in the Appendix at the end 
of this document.  Through this set of tasks, you will learn effective practices
for: data transformations, new variable construction, and the implementation of 
key decision rules.

### TASK STRUCTURE

The core of each task is a set of step-by-step instructions that guide you 
through the work. For each task you will find:

- Purpose --- Clarifies the importance of the task.  
- How to Start --- Identifies the input file(s) you will need to complete the 
task and guidelines for apply the task to your  own agency's data.
- Data Description --- Lists the data elements you will need to complete the 
task and describes the uniqueness of key data elements.
- Instructions --- Provides logical instructions on transforming the data with 
R code and fill-in-the-blank snapshots that help you visualize changes to 
your data.
- Solutions --- Provides answers for the data snapshot exercises.

After completing these tasks, you will be well-positioned to use your own 
agencyâ€™s data to construct similar clean research files needed in the Connect 
and Analyze stages.

Finally, if you find yourself in need of additional guidance, the friendly 
research team at SDP is available to help: `sdp@gse.harvard.edu`

## Task 1: STUDENT ATTRIBUTES
### PURPOSE

Through `Task 1: Student Attributes`, you will take the raw Student Attributes 
file and generate a cleaned Student Attributes output file that has only one 
observation per student. These data will allow you to examine college-going 
outcomes by race/ethnicity.

The core assignments of this task are to:

1. Resolve instances in which the same student appears with different values for 
race/ethnicity in different years. Our goal is to have only one race/ethnicity 
associated with each student.

2. Drop duplicate observations so the file is unique by student--that is, it 
contains only one observation per student. Upon completing this task, you will 
be have a clean Student_Attributes file that can then be used as to create the 
analysis file in Connect.  From Task 1, Task 2 is a natural next step, in which 
you will clean the Student_School_Year file in preparation for Task 3 and 
Task 4.

### HOW TO START
To begin, open the provided Student_Attributes practice file.

```{r echo=TRUE, results='asis'}
# Read in Stata
library(haven) # required for .dta files

# To read data from a zip file we create a connection to the path of the 
# zip file
tmpfileName <- "raw/Student_Demographics_Raw.dta"
con <- unz(description = "data/raw.zip", filename = tmpfileName, 
           open = "rb")
stuatt <- read_stata(con) # read data in the data subdirectory
```

The input file contains data for school years 2000-01 through 2006-07.  
Normally race is considered a time-invariant variable that is unique by student.  
In this instance, we deal with a case in which race is stored in a file unique 
by student and school year, which is instead time-variant.  This task aims to 
take convert the dataset from being time-variant to being time-invariant. 

If this is your first time going through the task, we recommend starting with 
the practice file, rather than your agency's own data file.  Doing so will help 
you learn SDP's cleaning methodology and allow you to easily check your answers 
from a common dataset.  You may then apply these methods to your agency's own 
`Student_Attributes` data with confidence.  To learn more about the data you 
will need to collect in your agency, refer to `Identify: Data Specification Guide` 
and the `DATA DESCRIPTION` section of this document.

In addition to the practice file, you may also find it useful to complete the 
data snapshot exercises provided in the task.  These exercises will allow you to 
visualize changes to the data occurring in each step of the task.  Solutions for 
the exercises are provided at the end of the task. 

### DATA DESCRIPTION

In Identify: Data Specification Guide, we specify the data elements included in 
the `Student_Attributes` research file.[^You may be wondering how  this specification 
compares to the  version in Identify: Data Specification Guide. Here are the 
primary changes: First, the `race_ethnicity` variable is coded as a string rather 
than being numeric, as specified in the Data Specification Guide.  You will 
correct this in the task as it will facilitate the process of making the file 
unique by sid.Second, we are examining a time-variant data set. In the Data 
Specification Guide, the `Student_Attributes` file is specified as being unique 
by sid.  In this case, the data are time-variant and unique by sid and 
`school_year`. Note that some districts may actually store `race_ethnicity` in a 
time-variant form such as this, and it is our job through this task to make the 
data time-invariant, i.e. each student only has a single value for `race_ethnicity` 
across time. Third, we are examining a partial data set including only `sid`, 
`school_year`, and `race_ethnicity`.  We do not include variables such as `male`, 
`hs_diploma`, or `hs_diploma_type`, or `hs_diploma_date` to simplify the task.  
These variables are essential for later analyses but are left for you to 
complete as a further exercise.For guidance on cleaning these additional 
variables, refer to the DECISION RULES GLOSSARY at the end of this document and 
use this task as a reference.]

In this task, we examine a partial version of the `Student_Attributes` file that 
includes only `sid`, `school_year`, and `race_ethnicity`. This partial version is 
presented to help you learn the `Student_Attributes` cleaning process to make a 
file unique by sid without having to worry about additional `Student_Attributes` 
variables such as `male`, `hs_diploma`, `hs_diploma_type`, or `hs_diploma_date`.  
The relevant variables and definitions you will need to complete the task are 
illustrated below:

```{r echo=TRUE}
dplyr::glimpse(stuatt)
```

**Uniqueness:** ideally, the data in its raw form would be unique by `sid`.  
However, this may not be the case as some agencies might record `race_ethnicity` 
in a time-variant manner, such as by school year. To address this, we explain 
how to take the raw research file from being unique by `sid` and `school_year` 
to being unique by `sid` alone.  Once the file is unique by `sid` alone, it is 
ready to be incorporated into the analysis file in the Connect stage.

Examine  your `Student_Attributes` raw research file input dataset.  According to 
the data specification, the file should be unique by `sid`.  Examine the snapshot 
below to determine if it is unique as described.  

```{r echo=TRUE}
head(stuatt)
# A quick way to test this in R
length(unique(stuatt$sid)) == nrow(stuatt)
```

```{r note1, include=FALSE}
# Optional--consider removing since R does not need factors to be recoded as 
# numeric. Recode the raw race\_ethnicity variable as numeric. Race\_ethnicity is 
# currently coded as a string variable, which is how some  agencies may store 
# this data . Replace the string values with numeric values as shown below. 
# This numeric race variable will be easier to use in later stages of the task. 
```

### Step 0: Read in the Data

```{r echo=TRUE, results='asis'}
# Read in Stata
library(haven) # required for .dta files

# To read data from a zip file we create a connection to the path of the 
# zip file
tmpfileName <- "raw/Student_Demographics_Raw.dta"
con <- unz(description = "data/raw.zip", filename = tmpfileName, 
           open = "rb")
stuatt <- read_stata(con) # read data in the data subdirectory
stuatt <- as.data.frame(stuatt)
```


Now drop the `first_9th_school_year_reported` variable. You will create a 
`first_9th_school_year_reported` variable in Task 3 that also imputes this 
variable for transfer-ins. 

```{r echo=TRUE, results='asis'}
stuatt$first_9th_school_year_reported <- NULL
idx <- c(2, 8552, 12506) # Specify which SIDs are interesting
stuatt[stuatt$sid %in% idx,]
```

#### Step 1 
*Create one consistent value for gender for each student across years*

```{r echo=TRUE, results='asis'}
library(dplyr) # this is the state-of-the-art in data manipulation in R
library(magrittr) # to improve code readability
stuatt %>% arrange(sid, school_year) %>% 
  select(sid, school_year, male) %>% 
  filter(sid %in% idx)

```

1. *Create a variable that shows how many unique values male assumes for each 
student. Name this variable `nvals_male`. Tabulate the variable and browse 
the relevant data.*


```{r}
stuatt <- stuatt %>% group_by(sid) %>% 
  mutate(nvals_male = length(unique(male))) %>% ungroup() 
table(stuatt$nvals_male)

stuatt %>% select(sid, school_year, male, nvals_male) %>% 
  filter(nvals_male > 1) 

# Or in RStudio
stuatt %>% select(sid, school_year, male, nvals_male) %>% 
  filter(nvals_male > 1) %>% View


```


2. *Identify the modal gender. If multiple modes exist for a student, report the 
most recent gender recorded*

```{r}
# First we need to create a 'mode' function in R that mimics Stata
# statamode creates a list of the modal values and assigns "."
# If more than one mode exists
statamode <- function(x) {
  z <- table(as.vector(x))
  m <- names(z)[z == max(z)]
  if(length(m) == 1){
    if(class(x) %in% c("numeric", "integer", "logical")){
      class(m) <- class(x)
    } else {
      class(m) <- "character"
    }
    
    return(m)
  }
  return(NA)
}

stuatt <- stuatt %>% group_by(sid) %>% 
  mutate(nvals_male = length(unique(male)), 
         male_mode = statamode(male)) %>% ungroup() 

stuatt %>% select(sid, male, male_mode, nvals_male) %>% 
  filter(sid %in% idx)

# In R, NA is equivalent to "." in Stata

```

```{r}
# Replace male with male_mode where male_mode is not missing
stuatt$male[!is.na(stuatt$male_mode)] <- stuatt$male_mode[!is.na(stuatt$male_mode)]
# In R we replace by vector so both sides of the <- have to have the same filter 
# so they are the same length

idx <- c(8552, 12506)

stuatt %>% select(sid, school_year, male, nvals_male, male_mode) %>% 
  filter(sid %in% idx)


# If multiple modes exist, report the most recent gender recorded

stuatt %<>% arrange(sid, school_year) %>% 
  group_by(sid) %>% 
  mutate(temp_male_last = male[school_year == max(school_year)])

# Show sid 12506
stuatt %>% select(sid, school_year, male, nvals_male, male_mode, temp_male_last) %>% 
  filter(sid == 12506)

# Assing temp_male_last to the male variable in cases where no mode exists
stuatt$male[is.na(stuatt$male_mode)] <- stuatt$temp_male_last[is.na(stuatt$male_mode)]


stuatt %>% select(sid, school_year, male, nvals_male, male_mode, temp_male_last) %>% 
  filter(sid == 12506)

# Drop temporary variables

stuatt %<>% select(-nvals_male, -male_mode, -temp_male_last)

```

Let's check we got it right

```{r}
table(stuatt$male)

# Check nvals without creating the variable

stuatt %>% ungroup %>% 
  group_by(sid) %>% 
  summarize(nvals = length(unique(male))) %>% select(nvals) %>% 
  table

length(unique(stuatt$sid))

```


##### Step 2
*Create one consistent value for race_ethnicicty for each student across years*

1. Recode the raw `race_ethnicity` variable as a numeric variable and label it. 
Replace the string race_ethnicity variable with the numeric one.


- 1 = African American, not Hispanic
- 2 = Asian American
- 3 = Hispanic
- 4 = American Indian
- 5 = White, not Hispanic
- 6 = Multiple / Other

```{r echo=TRUE}
# When R reads in Stata files using haven it creates a data type called 
# labelled, for compatibility with Stata and most R functions, we convert 
# this into a more standard factor variable

# Create a copy
stuatt$race_num <- stuatt$race_ethnicity
stuatt$race_ethnicity <- as_factor(stuatt$race_ethnicity)

table(stuatt$race_ethnicity) #check current values

stuatt$race_num <- NA
stuatt$race_num[stuatt$race_ethnicity=='B'] <- 1
stuatt$race_num[stuatt$race_ethnicity=='A'] <- 2
stuatt$race_num[stuatt$race_ethnicity=='H'] <- 3
stuatt$race_num[stuatt$race_ethnicity=='NA'] <- 4
stuatt$race_num[stuatt$race_ethnicity=='W'] <- 5
stuatt$race_num[stuatt$race_ethnicity=='M/O'] <- 6
table(stuatt$race_num)

idx <- c(8552)

stuatt %>% filter(sid %in% idx) %>% 
  select(sid, school_year, race_ethnicity, race_num)

```

```{r echo=TRUE,results='markup'}
# In R categorical variables are best represented as factors
# Factors can have values, and labels
# Create a labeled factor for the new race_num variable

stuatt$race_num2 <- factor(stuatt$race_num, 
                           labels = c('Black', 'Asian', 'Hispanic', 
                                    'Native American', 'White', 'MultipleOther'))

# Compare them to check using a cross-tabulation
table(stuatt$race_ethnicity, stuatt$race_num2)
# Replace them
stuatt$race_ethnicity <- stuatt$race_num2
stuatt$race_num2 <- NULL

table(stuatt$race_ethnicity) # counts
prop.table(table(stuatt$race_ethnicity))*100 #percentages
```


Check:  What does the distribution of your `race_ethnicity` variable look like? 
Let's redraw the tables above in a more readable format.

```{r echo=TRUE, results="markup"}
library(pander) # library to beautify output
pander(prop.table(table(stuatt$race_ethnicity))*100, style = "rmarkdown")
pander(table(stuatt$race_ethnicity), style = "rmarkdown")
```


Let's also draw a figure to show this distribution.

```{r echo=TRUE, fig.align='center'}
library(ggplot2) # the best R library for plotting

qplot(stuatt$race_ethnicity,geom='bar') + 
  theme_bw() + labs(x = 'Race/Ethnicity', y = 'Count', 
                    title = "Frequency of Student Race")
```


*2. Create a variable indicating how many unique values `race_ethnicity` 
assumes for each student called `nvals_race`.*

```{r echo=TRUE, eval=TRUE}
stuatt <- stuatt %>% group_by(sid) %>% 
  mutate(nvals_race = length(unique(race_ethnicity)))

table(stuatt$nvals_race)
```

```{r echo=TRUE}
qplot(as.factor(stuatt$nvals_race), geom='bar') + theme_bw() + 
  xlab('Unique Race Codes') + ylab('Count')

```

*3. Create a variable that shows how many unique values `race_ethnicity` 
assumes for each student and `school_year`. Name this variable `nvals_race_yr`. 
Tabulate the variable and browse the relevant data.*

```{r echo=TRUE, eval=TRUE}
stuatt <- stuatt %>% group_by(sid, school_year) %>% 
  mutate(nvals_race_yr = length(unique(race_ethnicity)))

table(stuatt$nvals_race_yr)

stuatt %>% select(sid, school_year, race_ethnicity, nvals_race, nvals_race_yr) %>%
  filter(nvals_race_yr > 1)

```


4. If more than one race is reported in the same school_year, report students as 
multiracial, unless one of their reported race_ethnicity values is Hispanic. 
Report the student as Hispanic in that case.

```{r}
# Generate a temporary hispanic variable
stuatt$temp_ishispanic <- ifelse(stuatt$race_num == 3 & stuatt$nvals_race_yr > 1, 1, 0)

stuatt %>% select(sid, school_year, race_ethnicity, nvals_race, nvals_race_yr, 
                  temp_ishispanic) %>%
  filter(nvals_race_yr > 1)

stuatt %<>% group_by(sid, school_year) %>% 
  mutate(ishispanic = max(temp_ishispanic, na.rm=TRUE))

stuatt %>% select(sid, school_year, race_ethnicity, nvals_race, nvals_race_yr, 
                  temp_ishispanic, ishispanic) %>%
  filter(nvals_race_yr > 1)

# Replace hispanic values

stuatt$race_num[stuatt$nvals_race_yr > 1 & stuatt$ishispanic == 1] <- 3
stuatt$race_ethnicity[stuatt$nvals_race_yr > 1 & stuatt$ishispanic == 1] <- "Hispanic"
stuatt$race_num[stuatt$nvals_race_yr > 1 & stuatt$ishispanic != 1] <- 6
stuatt$race_ethnicity[stuatt$nvals_race_yr > 1 & stuatt$ishispanic != 1] <- "MultipleOther"

# Drop the temporary variables
stuatt <- select(stuatt, -ishispanic, -temp_ishispanic)

# Drop the duplicates resulting from fixing student with different race_ethnicity
# within a school year

stuatt <- bind_rows(stuatt %>% filter(nvals_race_yr < 2), 
                    stuatt %>% filter(nvals_race_yr > 1) %>% 
                      distinct(sid, school_year, race_ethnicity, .keep_all=TRUE))
stuatt <- select(stuatt, -nvals_race_yr)
# Re arrange
stuatt %<>% arrange(sid, school_year)
```

##- TODO -## Check that this worked

*5 Report the modal race. If multiple modes exist for a student, report the most 
recent race recorded.*

```{r echo=TRUE, results='markup'}
# Create new data frame for individual student
# Create nvals while we are at it

stuatt %<>% group_by(sid) %>% 
  mutate(race_mode = statamode(race_ethnicity))

# tab1 <- table(modes$race_temp,modes$nvals)
# addmargins(tab1, FUN=list(Total=sum), quiet=TRUE)

stuatt %>% filter(sid == 8552) %>% 
  select(sid, school_year, race_ethnicity, nvals_race, race_mode)

stuatt$race_ethnicity[!is.na(stuatt$race_mode)] <- stuatt$race_mode[!is.na(stuatt$race_mode)]

stuatt %>% filter(sid == 8552) %>% 
  select(sid, school_year, race_ethnicity, nvals_race, race_mode)


# Consider cases where the mode is not unique
stuatt %>% filter(sid == 2) %>% 
  select(sid, school_year, race_ethnicity, nvals_race, race_mode)

```


```{r}
# If multiple modes exist report th emost recent race recorded

stuatt %<>% group_by(sid) %>% 
  mutate(race_last = race_ethnicity[school_year == max(school_year)])

stuatt %>% filter(sid == 2) %>% 
  select(sid, school_year, race_ethnicity, nvals_race, race_mode, race_last)

stuatt$race_ethnicity[is.na(stuatt$race_mode)] <- stuatt$race_last[is.na(stuatt$race_mode)]

stuatt %>% filter(sid %in% c(8552, 2)) %>% 
  select(sid, school_year, race_ethnicity)

# Drop temporary variables

stuatt %<>% select(-nvals_race, -race_mode, -race_last, -race_num)
```


```{r}
table(stuatt$race_ethnicity)
```

#### Step 3
*Create consistent values for high school diploma variables.*

// 1. Recode the `hs_diploma_type variable` as a numeric variable and 
label it. Replace the string `hs_diploma_type` variable with the 
numeric one. Use lower numbers for more competitive diploma types.
